{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Capter10 隐马尔可夫模型\n",
    "## HMM模型\n",
    "### 另外参考[umdhmm](http://www.kanungo.com/software/software.html#umdhmm)，[52nlp](https://www.52nlp.cn/category/hidden-markov-model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class HMM():\n",
    "    def forward(self, PI, A, B, O):\n",
    "        mid_prob = []\n",
    "        N = A.shape[0]\n",
    "        T = len(O)\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                mid_prob.append(PI * B[:, O[t]])\n",
    "            else:\n",
    "                mid_prob.append([])\n",
    "                for i in range(N):\n",
    "                    mid_prob[t].append(np.inner(mid_prob[t - 1], A[:, i])*B[i][O[t]])\n",
    "        return np.sum(mid_prob[T - 1])\n",
    "\n",
    "    def viterbi(self, PI, A, B, O):\n",
    "        mid_prob = []\n",
    "        stat_info = []\n",
    "        N = A.shape[0]\n",
    "        M = B.shape[1]\n",
    "        T = len(O)\n",
    "        for t in range (T):\n",
    "            stat_info.append([])\n",
    "            if t == 0:\n",
    "                mid_prob.append(PI * B[:, O[0]])\n",
    "            else:\n",
    "                mid_prob.append([])\n",
    "                for i in range(N):\n",
    "                    s_p = mid_prob[t - 1] * A[:, i]\n",
    "                    stat_info[t].append({'val':np.max(s_p), 'idx':np.argmax(s_p)})\n",
    "                    mid_prob[t].append(stat_info[t][i]['val'] * B[i][O[t]])\n",
    "        path = []\n",
    "        path.append(np.argmax(mid_prob[T - 1]))\n",
    "        for t in range(T - 2, -1, -1):\n",
    "            path.append(stat_info[t+1][path[T-2-t]]['idx'])\n",
    "        path.reverse()\n",
    "        return path\n",
    "\n",
    "    def forward_scale(self, PI, A, B, O):\n",
    "        mid_prob = []\n",
    "        scale = []\n",
    "        N = A.shape[0]\n",
    "        T = len(O)\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                mid_prob.append(PI * B[:, O[t]])\n",
    "            else:\n",
    "                mid_prob.append([])\n",
    "                for i in range(N):\n",
    "                    mid_prob[t].append(np.inner(mid_prob[t - 1], A[:, i])*B[i][O[t]])\n",
    "            scale.append(np.sum(mid_prob[t]))\n",
    "            mid_prob[t] = mid_prob[t] / scale[t]\n",
    "        return (np.array(mid_prob), np.array(scale), np.sum(np.log(scale)))\n",
    "\n",
    "    def backward_scale(self, PI, A, B, O, scale):\n",
    "        mid_prob = []\n",
    "        N = A.shape[0]\n",
    "        T = len(O) - 1\n",
    "        mid_prob.append(np.ones(N) * (1.0/scale[T]))\n",
    "        for t in range (T, 0, -1):\n",
    "            mid_prob.append([])\n",
    "            for j in range(N):\n",
    "                prob = np.sum(A[j, :] * B[:, O[t]] * mid_prob[T - t])\n",
    "                mid_prob[T-t+1].append(prob / scale[t - 1])\n",
    "        mid_prob.reverse()\n",
    "        return np.array(mid_prob)\n",
    "\n",
    "    def cal_gamma(self, O, alpha, beta):\n",
    "        T = len(O)\n",
    "        gamma = []\n",
    "        for t in range (T):\n",
    "            gamma.append(alpha[t] * beta[t])\n",
    "            g_sum = np.sum(gamma[t])\n",
    "            gamma[t] = gamma[t] / g_sum\n",
    "        return np.array(gamma)\n",
    "\n",
    "    def cal_xi(self, A, B, O, alpha, beta):\n",
    "        xi = []\n",
    "        T = len(O)\n",
    "        for t in range(T - 1):\n",
    "            res = []\n",
    "            for i in range(A.shape[0]):\n",
    "                res.append(alpha[t][i] * beta[t+1] * A[i, :] * B[:, O[t+1]])\n",
    "            res_sum = np.sum(res)\n",
    "            xi.append(res/res_sum)\n",
    "        return np.array(xi)\n",
    "\n",
    "    def BaumWelch(self, O, N, M, eps = 0.001):\n",
    "        T = len(O)\n",
    "        PI = np.random.rand(N)\n",
    "        val_sum = np.sum(PI)\n",
    "        PI = PI/val_sum\n",
    "        A = np.random.rand(N, N)\n",
    "        val_sum = np.sum(A, axis=1)\n",
    "        for i in range(N):\n",
    "            A[i] = A[i, :] / val_sum[i]\n",
    "        B = np.random.rand(N, M)\n",
    "        val_sum = np.sum(B, axis=1)\n",
    "        for i in range(M):\n",
    "            B[i] = B[i, :] / val_sum[i]\n",
    "\n",
    "        old_prob = -1\n",
    "        iter_num = 0\n",
    "        while True:\n",
    "            alpha, scale, prob = self.forward_scale(PI, A, B, O)\n",
    "            if old_prob == -1:\n",
    "                old_prob = prob\n",
    "            else:\n",
    "                if abs(prob - old_prob) < eps:\n",
    "                    break\n",
    "            beta = self.backward_scale(PI, A, B, O, scale)\n",
    "            gamma =self.cal_gamma(O, alpha, beta)\n",
    "            xi = self.cal_xi(A, B, O, alpha, beta)\n",
    "            PI = 0.001 + 0.999 * gamma[0, :]\n",
    "            A_sum = np.sum(gamma[:T-1, :], axis = 0)\n",
    "            A_val = np.sum(xi[:T-1, :], axis = 0)\n",
    "            B_sum = np.sum(gamma, axis = 0)\n",
    "            for i in range(N):\n",
    "                A[i] = 0.001 + 0.999 * A_val[i] / A_sum[i]\n",
    "                for k in range(M):\n",
    "                    B_val = 0.0\n",
    "                    for t in range(T):\n",
    "                        if O[t] == k:\n",
    "                            B_val = B_val + gamma[t][i]\n",
    "                    B[i][k] = 0.001 + 0.999 * B_val / B_sum[i]\n",
    "            print(\"loop: %d, prob: %lf, prob_diff: %lf\" % (iter_num, prob, abs(prob - old_prob)))\n",
    "            iter_num = iter_num + 1\n",
    "            old_prob = prob\n",
    "        return (PI, A, B)"
   ]
  },
  {
   "source": [
    "## 算法测试\n",
    "### 简单测试用例"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "概率：0.130218\n\n学习：\n原始参数概率：0.001025\nloop: 0, prob: -7.511149, prob_diff: 0.000000\nloop: 1, prob: -6.933003, prob_diff: 0.578146\nloop: 2, prob: -6.862454, prob_diff: 0.070549\nloop: 3, prob: -6.814729, prob_diff: 0.047725\nloop: 4, prob: -6.766552, prob_diff: 0.048177\nloop: 5, prob: -6.705045, prob_diff: 0.061507\nloop: 6, prob: -6.617510, prob_diff: 0.087535\nloop: 7, prob: -6.481943, prob_diff: 0.135567\nloop: 8, prob: -6.255157, prob_diff: 0.226786\nloop: 9, prob: -5.882904, prob_diff: 0.372253\nloop: 10, prob: -5.398239, prob_diff: 0.484665\nloop: 11, prob: -4.984953, prob_diff: 0.413286\nloop: 12, prob: -4.731295, prob_diff: 0.253658\nloop: 13, prob: -4.564830, prob_diff: 0.166465\nloop: 14, prob: -4.429306, prob_diff: 0.135523\nloop: 15, prob: -4.314001, prob_diff: 0.115306\nloop: 16, prob: -4.223092, prob_diff: 0.090909\nloop: 17, prob: -4.159117, prob_diff: 0.063975\nloop: 18, prob: -4.118940, prob_diff: 0.040176\nloop: 19, prob: -4.096003, prob_diff: 0.022938\nloop: 20, prob: -4.083772, prob_diff: 0.012231\nloop: 21, prob: -4.077511, prob_diff: 0.006261\nloop: 22, prob: -4.074359, prob_diff: 0.003152\nloop: 23, prob: -4.072767, prob_diff: 0.001592\n学习后参数：PI=[0.00125107 0.99974793 0.001001  ]\n, A=[[0.60920618 0.00149375 0.39130007]\n [0.37600559 0.62419267 0.00180173]\n [0.00234567 0.00106388 0.99859045]]\n, B=[[0.70295173 0.29804827]\n [0.99943546 0.00156454]\n [0.11372651 0.88727349]]\n学习参数概率：0.017044\n\n预测:  [3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "# 问题1:概率计算（使用第一版书本章例子）\n",
    "A = np.array([[0.5, 0.2, 0.3], [0.3, 0.5, 0.2], [0.2, 0.3, 0.5]])\n",
    "B = np.array([[0.5, 0.5], [0.4, 0.6], [0.7, 0.3]])\n",
    "PI = [0.2, 0.4, 0.4]\n",
    "O = [0, 1, 0]\n",
    "model = HMM()\n",
    "print('概率：%f\\n' % (model.forward(PI, A, B, O)))\n",
    "\n",
    "# 问题2: 无监督学习\n",
    "O = [0,0,0,0,1,0,1,1,1,1]\n",
    "print('学习：')\n",
    "print('原始参数概率：%f' % (model.forward(PI, A, B, O)))\n",
    "PI1, A1, B1 = model.BaumWelch(O, 3, 2)\n",
    "print(\"学习后参数：PI={}\\n, A={}\\n, B={}\".format(PI1, A1, B1))\n",
    "print('学习参数概率：%f\\n' % (model.forward(PI1, A1, B1, O)))\n",
    "\n",
    "# 问题3: 预测 （使用第一版书本章例子）\n",
    "O = [0, 1, 0]\n",
    "print('预测: ', [x+1 for x in model.viterbi(PI, A, B, O)])"
   ]
  },
  {
   "source": [
    "### HMM在分词上的应用示例"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 我们  希望  ，  新  世纪  成为  各国  人民  共享  和平  的  世纪  。  在20世纪  里  ，  世界  饱受  各种  战争  和  冲突  的  苦难  。 \n 北京  新年  音乐会  展现  经典  魅力  尉  健行  李  岚清  与  数千  首  都  观众  一起  欣赏  。 \n 本届  冰雪节  第一  次  升格  为  国际  级  冰雪  盛会  ，  来  自20多  个  国家  的  使节  云集  冰城  ；  盛会  还  吸引  了  美国  、  日本  、  俄罗斯等国  的  冰雪  爱  好者  。 \n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "train_raw = open('data/pku_training.utf8').read()\n",
    "\n",
    "#begin:B, middle:M, end:E, single:S\n",
    "Hide = namedtuple('Hide', 'B, M, E, S')\n",
    "hide_stat = Hide(0, 1, 2, 3)\n",
    "words = set(train_raw)\n",
    "words.remove('\\n')\n",
    "words.remove(' ')\n",
    "words = list(words)\n",
    "words_dict = {words[i] : i for i, w in enumerate(words)}\n",
    "words_idx_dict = {v : k for k, v in words_dict.items()}\n",
    "\n",
    "def get_hmm_params():\n",
    "    train_lines = train_raw.split('\\n')\n",
    "    PI_num = []\n",
    "    A_num = []\n",
    "    B_num = []\n",
    "    for i in range(len(hide_stat)):\n",
    "        PI_num.append(0)\n",
    "        a = [0] * len(hide_stat)\n",
    "        A_num.append(a)\n",
    "        b = [0] * len(words)\n",
    "        B_num.append(b)\n",
    "\n",
    "    for l in train_lines:\n",
    "        flds = l.split(' ')\n",
    "        first = True\n",
    "        lst_stat = None\n",
    "        for fld in flds:\n",
    "            if len(fld) == 1:\n",
    "                cur_stat = hide_stat.S\n",
    "                if first:\n",
    "                    PI_num[cur_stat] += 1\n",
    "                else:\n",
    "                    A_num[lst_stat][cur_stat] += 1\n",
    "                B_num[cur_stat][words_dict[fld]] += 1\n",
    "                lst_stat = cur_stat\n",
    "            else:\n",
    "                if first:\n",
    "                    PI_num[hide_stat.B] += 1\n",
    "                w_list = list(fld)\n",
    "                for i, w in enumerate(w_list):\n",
    "                    if i == 0:\n",
    "                        cur_stat = hide_stat.B\n",
    "                    elif i == len(w_list) - 1:\n",
    "                        cur_stat = hide_stat.E\n",
    "                    else:\n",
    "                        cur_stat = hide_stat.M\n",
    "                    B_num[cur_stat][words_dict[w]] += 1\n",
    "                    if lst_stat != None:\n",
    "                        A_num[lst_stat][cur_stat] += 1\n",
    "                    lst_stat = cur_stat\n",
    "            first = False\n",
    "\n",
    "    PI = np.array(PI_num)\n",
    "    PI = PI/np.sum(PI)\n",
    "    A = np.array(A_num)\n",
    "    A = A/np.sum(A, axis=0)\n",
    "    B = np.array(B_num)\n",
    "    B = B/(np.sum(B, axis = 1).reshape([4,1]))\n",
    "    return (PI, A, B)\n",
    "\n",
    "def print_output(O, hides):\n",
    "    output = ''\n",
    "    for i, s in enumerate(hides):\n",
    "        w = words_idx_dict[O[i]]\n",
    "        if s == hide_stat.B:\n",
    "            output += ' '+w\n",
    "        elif s == hide_stat.M:\n",
    "            output += w\n",
    "        elif s == hide_stat.E:\n",
    "            output += w+' '\n",
    "        else:\n",
    "            output += ' ' + w + ' '\n",
    "    print(output)\n",
    "\n",
    "inputs = ['我们希望，新世纪成为各国人民共享和平的世纪。在20世纪里，世界饱受各种战争和冲突的苦难。',\n",
    "    '北京新年音乐会展现经典魅力尉健行李岚清与数千首都观众一起欣赏。',\n",
    "    '本届冰雪节第一次升格为国际级冰雪盛会，来自20多个国家的使节云集冰城；盛会还吸引了美国、日本、俄罗斯等国的冰雪爱好者。']\n",
    "PI, A, B = get_hmm_params()\n",
    "model = HMM()\n",
    "for test_str in inputs:\n",
    "    O = [words_dict[w] for w in test_str]\n",
    "    hides = model.viterbi(PI, A, B, O)\n",
    "    print_output(O, hides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}